# Transformer æ–‡æœ¬æ‘˜è¦ - CNN/DailyMail

åŸºäº Transformer çš„æ–°é—»æ–‡æœ¬æ‘˜è¦æ¨¡å‹ï¼Œåœ¨ CNN/DailyMail æ•°æ®é›†ä¸Šè®­ç»ƒã€‚

## ğŸ“ é¡¹ç›®ç»“æ„

```
home_work/
â”œâ”€â”€ src/
â”‚   â”œâ”€â”€ model.py          # Transformer æ¨¡å‹å®šä¹‰
â”‚   â”œâ”€â”€ trainer.py        # è®­ç»ƒå™¨
â”‚   â””â”€â”€ tester.py         # æµ‹è¯•å™¨ï¼ˆæ¨ç†å’Œè¯„ä¼°ï¼‰
â”œâ”€â”€ dataset/
â”‚   â”œâ”€â”€ dataset.py        # CNN/DailyMail æ•°æ®é›†åŠ è½½
â”‚   â”œâ”€â”€ train/            # è®­ç»ƒé›†ï¼ˆ287,113 æ ·æœ¬ï¼‰
â”‚   â”œâ”€â”€ validation/       # éªŒè¯é›†ï¼ˆ13,368 æ ·æœ¬ï¼‰
â”‚   â””â”€â”€ test/             # æµ‹è¯•é›†ï¼ˆ11,490 æ ·æœ¬ï¼‰
â”œâ”€â”€ scripts/
â”‚   â””â”€â”€ run.sh            # å¿«é€Ÿè¿è¡Œè„šæœ¬
â”œâ”€â”€ results/              # æ¨¡å‹ä¿å­˜ç›®å½•
â”œâ”€â”€ config.yaml           # é…ç½®æ–‡ä»¶ï¼ˆYAMLæ ¼å¼ï¼‰
â”œâ”€â”€ main.py               # ä¸»ç¨‹åºï¼ˆè®­ç»ƒ+æµ‹è¯•ï¼‰
â”œâ”€â”€ requirements.txt      # Python ä¾èµ–
â””â”€â”€ README.md             # æœ¬æ–‡ä»¶
```

## ğŸ”§ ç¯å¢ƒé…ç½®

### å®‰è£…ä¾èµ–

```bash

conda create -n transformer python=3.10
conda activate transformer
conda install pytorch torchvision torchaudio pytorch-cuda=11.8 -c pytorch -c nvidia
pip install -r requirements.txt
```

éœ€è¦çš„åŒ…ï¼š
- torch >= 2.0.0
- datasets >= 2.14.0
- tqdm >= 4.65.0
- numpy >= 1.24.0
- rouge-score >= 0.1.2
- nltk >= 3.8
- matplotlib >= 3.7.0
- pyyaml >= 6.0

## ğŸš€ å¿«é€Ÿå¼€å§‹

### 1. è®­ç»ƒæ¨¡å‹

```bash
python main.py --mode train --config config.yaml
```

ä»æ£€æŸ¥ç‚¹æ¢å¤è®­ç»ƒï¼š

```bash
python main.py --mode train --resume results/latest_model.pt
```

### 2. æµ‹è¯•æ¨¡å‹ï¼ˆç”Ÿæˆæ‘˜è¦ï¼‰

```bash

# æ‰§è¡Œ ROUGE è¯„ä¼°
python main.py --mode test --evaluate --num_samples 1000

# ä¿å­˜æµ‹è¯•ç»“æœ
python main.py --mode test --save_results --show_examples

# ä½¿ç”¨æŒ‡å®šæ£€æŸ¥ç‚¹
python main.py --mode test --checkpoint results/best_model.pt --show_examples
```

### 3. å®Œæ•´æµç¨‹ï¼ˆä½¿ç”¨è„šæœ¬ï¼‰

```bash
bash scripts/run.sh
```

## âš™ï¸ é…ç½®è¯´æ˜

æ‰€æœ‰é…ç½®éƒ½åœ¨ `config.yaml` æ–‡ä»¶ä¸­ç®¡ç†ï¼ŒåŒ…æ‹¬ï¼š

### æ•°æ®é…ç½®
- `dataset_path`: æ•°æ®é›†è·¯å¾„
- `max_vocab_size`: æœ€å¤§è¯æ±‡é‡ï¼ˆé»˜è®¤ 50,000ï¼‰
- `src_max_len`: æºåºåˆ—æœ€å¤§é•¿åº¦ï¼ˆé»˜è®¤ 512ï¼‰
- `tgt_max_len`: ç›®æ ‡åºåˆ—æœ€å¤§é•¿åº¦ï¼ˆé»˜è®¤ 150ï¼‰

### æ¨¡å‹é…ç½®
- `d_model`: åµŒå…¥ç»´åº¦ï¼ˆé»˜è®¤ 256ï¼‰
- `num_heads`: æ³¨æ„åŠ›å¤´æ•°ï¼ˆé»˜è®¤ 8ï¼‰
- `num_layers`: Encoder/Decoder å±‚æ•°ï¼ˆé»˜è®¤ 4ï¼‰
- `d_ff`: å‰é¦ˆç½‘ç»œç»´åº¦ï¼ˆé»˜è®¤ 1024ï¼‰
- `dropout`: Dropout ç‡ï¼ˆé»˜è®¤ 0.1ï¼‰

### è®­ç»ƒé…ç½®
- `batch_size`: æ‰¹æ¬¡å¤§å°ï¼ˆé»˜è®¤ 8ï¼‰
- `num_epochs`: è®­ç»ƒè½®æ•°ï¼ˆé»˜è®¤ 10ï¼‰
- `learning_rate`: å­¦ä¹ ç‡ï¼ˆé»˜è®¤ 0.0001ï¼‰
- `warmup_steps`: é¢„çƒ­æ­¥æ•°ï¼ˆé»˜è®¤ 4000ï¼‰
- `label_smoothing`: æ ‡ç­¾å¹³æ»‘ï¼ˆé»˜è®¤ 0.1ï¼‰

### æµ‹è¯•é…ç½®
- `batch_size`: æµ‹è¯•æ‰¹æ¬¡å¤§å°ï¼ˆé»˜è®¤ 16ï¼‰
- `decode_method`: è§£ç æ–¹æ³•ï¼ˆ`greedy` æˆ– `beam_search`ï¼‰
- `beam_width`: Beam Search å®½åº¦ï¼ˆé»˜è®¤ 5ï¼‰
- `max_generate_len`: æœ€å¤§ç”Ÿæˆé•¿åº¦ï¼ˆé»˜è®¤ 150ï¼‰

å¯ä»¥ç›´æ¥ç¼–è¾‘ `config.yaml` æ¥è°ƒæ•´è¿™äº›å‚æ•°ã€‚

## ğŸ“Š æ•°æ®é›†ä¿¡æ¯

**CNN/DailyMail 3.0.0**

- **æ•°æ®é›†é“¾æ¥**: https://huggingface.co/datasets/cnn_dailymail
- **ä»»åŠ¡**: æ–°é—»æ–‡æœ¬æ‘˜è¦ï¼ˆAbstractive Summarizationï¼‰
- **æ ¼å¼**: 
  - è¾“å…¥ï¼ˆarticleï¼‰: æ–°é—»æ–‡ç« å…¨æ–‡
  - è¾“å‡ºï¼ˆhighlightsï¼‰: æ–‡ç« æ‘˜è¦
- **æ•°æ®é‡**:
  - è®­ç»ƒé›†: 287,113 æ¡
  - éªŒè¯é›†: 13,368 æ¡
  - æµ‹è¯•é›†: 11,490 æ¡


## ğŸ—ï¸ æ¨¡å‹æ¶æ„

æ ‡å‡† Transformer Encoder-Decoder æ¶æ„ï¼š

### Encoder
- Multi-Head Self-Attention
- Position-wise Feed-Forward
- Layer Normalization
- Residual Connection
- Positional Encoding (æ­£å¼¦ä½™å¼¦)

### Decoder
- Masked Multi-Head Self-Attention
- Multi-Head Cross-Attention
- Position-wise Feed-Forward
- Layer Normalization
- Residual Connection
- Positional Encoding

### å…³é”®è®¾è®¡
- **ä½ç½®ç¼–ç **: ä½¿ç”¨æ­£å¼¦ä½™å¼¦å‡½æ•°ï¼Œæ”¯æŒä»»æ„é•¿åº¦åºåˆ—
- **ç¼©æ”¾**: Embedding ä¹˜ä»¥ âˆšd_model å¹³è¡¡ä½ç½®ç¼–ç 
- **Mask**: 
  - Padding mask: å±è”½å¡«å……ä½ç½®
  - No-peek mask: é˜²æ­¢ Decoder çœ‹åˆ°æœªæ¥ä¿¡æ¯
- **æ ‡ç­¾å¹³æ»‘**: label_smoothing=0.1 æé«˜æ³›åŒ–
- **å­¦ä¹ ç‡è°ƒåº¦**: Warmup + Decayï¼ˆTransformer åŸè®ºæ–‡ç­–ç•¥ï¼‰


## ğŸ“ è®¸å¯è¯

MIT License
